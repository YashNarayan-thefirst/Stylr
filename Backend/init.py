#!/usr/bin/env python3
#
#   Our data comes from:
#
#       https://www.kaggle.com/api/v1/datasets/download/paramaggarwal/fashion-product-images-dataset
#
#   ...which in turn was generated by scraping `www.myntra.com`.
#
# IMAGES
#
#   Unless we're going to use some sort of visual machine-learning algorithm,
#   it's probably best just to use the images hosted on the Myntra servers.
#   These images are served with `Access-Control-Allow-Origin: *`,
#   so we can just point the browser directly to that site and
#   skip having to deal with the images at all on our end.
#   The URLs all seem to follow this format:
#
#       http://assets.myntassets.com/...
#
#   It should be noted that it's possible to get a different resolution by
#   stripping off an initial `v1/` from the pathname (if it exists) and
#   prepending `h_{height},q_{quality_percentage},w_{width}/v1/`,
#   where items in brackets are adjustable parameters.
#
# FILES
#
#   This script downloads the data required by the application and
#   performs some minimal data processing. All files are written into
#   the `data` directory.
#
#   These files contain raw data:
#
#     - styles.csv: list of clothing articles and metadata
#     - images.csv: mapping between filenames and image URLs
#
#   This script simply combines them into a single file:
#
#     - items.csv
#

import collections
import io
import optparse
import os
import shutil
import urllib.request
import zipfile

base_url = "https://www.kaggle.com/api/v1/datasets/download/paramaggarwal/fashion-product-images-dataset/fashion-dataset%2f"
data_dir = "data"
files = ["styles.csv", "images.csv"]

def assert_removeprefix(s, prefix):
    assert s.startswith(prefix)
    return s[len(prefix):]

def main():
    parser = optparse.OptionParser()
    parser.add_option("-f", "--force", action="store_true", help="download files even if they exist")
    opts, args = parser.parse_args()
    if args:
        parser.error(f"unexpected argument {args[0]!r}")

    try:
        os.mkdir(data_dir)
    except FileExistsError:
        pass

    os.chdir(data_dir)

    for file in files:
        if not opts.force and os.path.exists(file):
            continue
        url = base_url + file
        print(f"Downloading {url}")
        buffer = io.BytesIO()
        with urllib.request.urlopen(url) as response:
            shutil.copyfileobj(response, buffer)
        print(f"Extracting {file}")
        zipfile.ZipFile(buffer).extract(file)

    items = {}

    with open("styles.csv", "rb") as file:
        file.readline()
        for line in file:
            line = line[:-1]
            fields = line.split(b",", 9)
            assert len(fields) == 10
            fields[9] = fields[9].replace(b",", b"")
            fields.append(None)
            items[fields[0]] = fields

    with open("images.csv", "rb") as file:
        file.readline()
        for line in file:
            line = line[:-1]
            [id, url] = line.split(b",")
            id = id[:-4]
            if url == b"undefined":
                del items[id]
                continue
            url = assert_removeprefix(url, b"http://assets.myntassets.com/")
            url = url.removeprefix(b"v1/")
            items[id][10] = url

    with open("items.csv", "wb") as file:
        for fields in items.values():
            file.write(b",".join(fields))
            file.write(b"\n")

if __name__ == "__main__":
    main()
