#!/usr/bin/env python3
#
#   Our data comes from:
#
#       https://www.kaggle.com/api/v1/datasets/download/paramaggarwal/fashion-product-images-dataset
#
#   ...which in turn was generated by scraping `www.myntra.com`.
#
# IMAGES
#
#   Unless we're going to use some sort of visual machine-learning algorithm,
#   it's probably best just to use the images hosted on the Myntra servers.
#   These images are served with `Access-Control-Allow-Origin: *`,
#   so we can just point the browser directly to that site and
#   skip having to deal with the images at all on our end.
#   The URLs all seem to follow this format:
#
#       http://assets.myntassets.com/...
#
#   It should be noted that it's possible to get a different resolution by
#   stripping off an initial `v1/` from the pathname (if it exists) and
#   prepending `h_{height},q_{quality_percentage},w_{width}/v1/`,
#   where items in brackets are adjustable parameters.
#
# FILES
#
#   This script downloads the data required by the application and
#   performs some minimal data processing. All files are written into
#   the `data` directory.
#
#   These files contain raw data:
#
#     - styles.csv: list of clothing articles and metadata
#     - images.csv: mapping between filenames and image URLs
#
#   This script simply combines them into a single file:
#
#     - items.csv
#

from collections import defaultdict
import io
import optparse
import os
import shutil
import sys
import urllib.request
import zipfile

base_url = "https://www.kaggle.com/api/v1/datasets/download/paramaggarwal/fashion-product-images-dataset/fashion-dataset%2f"
data_dir = "data"
files = ["styles.csv", "images.csv"]

def assert_removeprefix(s, prefix):
    assert s.startswith(prefix)
    return s[len(prefix):]

def assert_removesuffix(s, suffix):
    assert s.endswith(suffix)
    return s[:-len(suffix)]

def scoreboard(d):
    return {key: i + 1 for i, key in enumerate(
        sorted(d, key=lambda key: d[key], reverse=True)
    )}

def dump_js_list(file, name, values):
    file.write(b"export const " + name + b" = {\n")
    for value in values:
        file.write(b"  \"" + value + b"\",\n")
    file.write(b"];\n")

def main():
    parser = optparse.OptionParser()
    parser.add_option("-f", "--force", action="store_true", help="download files even if they exist")
    parser.add_option("-n", "--dry-run", action="store_true", help="don't write composite file")
    opts, args = parser.parse_args()
    if args:
        parser.error(f"unexpected argument {args[0]!r}")

    try:
        os.mkdir(data_dir)
    except FileExistsError:
        pass

    os.chdir(data_dir)

    for file in files:
        if not opts.force and os.path.exists(file):
            continue
        url = base_url + file
        print(f"Downloading {url}")
        buffer = io.BytesIO()
        with urllib.request.urlopen(url) as response:
            shutil.copyfileobj(response, buffer)
        print(f"Extracting {file}")
        zipfile.ZipFile(buffer).extract(file)

    items = {}
    categories = defaultdict(int)
    colors = defaultdict(int)
    usages = defaultdict(int)
    num_no_image = 0
    max_name = 0
    max_url = 0
    max_text = 0

    gender_map = {
        b"Women": 1,
        b"Men": 2,
        b"Girls": 3,
        b"Boys": 4,
        b"Unisex": 5
    }

    with open("styles.csv", "rb") as file:
        file.readline()
        for line in file:
            id, gender, cat1, cat2, cat3, color, season, year, usage, name = line.split(b",", 9)
            gender = gender_map[gender]
            categories[cat1] += 1
            categories[cat2] += 1
            categories[cat3] += 1
            if not color or color == b"NA":
                color = None
            else:
                colors[color] += 1
            if not usage or usage == b"NA":
                usage = None
            else:
                usages[usage] += 1
            name = name.strip().replace(b",", b";")
            if len(name) > max_name:
                max_name = len(name)
            if id in items:
                sys.stderr.write(f"duplicate item {id!r}")
            else:
                items[id] = [id, name, None, gender, cat1, cat2, cat3, color, usage]

    with open("images.csv", "rb") as file:
        file.readline()
        for line in file:
            id, url = line.split(b",")
            id = assert_removesuffix(id, b".jpg")
            url = url.strip()
            if url == b"undefined":
                del items[id]
                num_no_image += 1
                continue
            url = assert_removeprefix(url, b"http://assets.myntassets.com/")
            if url.startswith(b"v1/"):
                url = url[3:]
            if len(url) > max_url:
                max_url = len(url)
            item = items[id]
            if len(item[1]) + len(url) > max_text:
                max_text = len(item[1]) + len(url)
            item[2] = url

    sys.stdout.write(
        f"{len(items)} items\n"
        f"{num_no_image} missing images\n"
        f"{len(categories)} categories\n"
        f"{len(colors)} colors\n"
        f"{len(usages)} usages\n"
        f"max name: {max_name}\n"
        f"max url: {max_url}\n"
        f"max text: {max_text}\n"
    )

    if opts.dry_run:
        return

    categories = scoreboard(categories)
    colors = scoreboard(colors)
    usages = scoreboard(usages)

    with open("filters.js", "wb") as file:
        dump_js_list(file, b"categories", categories)
        dump_js_list(file, b"colors", colors)
        dump_js_list(file, b"usages", usages)

    with open("items", "wb") as file:
        for id, name, url, gender, cat1, cat2, cat3, color, usage in items.values():
            cats = [categories[cat] for cat in {cat1, cat2, cat3}]
            while len(cats) < 3:
                cats.append(0)
            file.write(bytes([
                (gender << 4) | (usages[usage] if usage is not None else 0),
                colors[color] if color is not None else 0,
                *cats,
                len(name),
                len(url)
            ]) + name + url + b" " * (248 - len(name) - len(url)) + b"\n")

if __name__ == "__main__":
    main()
